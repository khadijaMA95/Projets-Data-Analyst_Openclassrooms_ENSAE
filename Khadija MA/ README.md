# Projets formation Data-Analyst Openclassrooms_ENSAE
Bonjour :wave:	

Ce Portfolio contient les  projets que j'ai réalisé dans le cadre de ma formation Data Analyst avec Openclassrooms-ENSAE, la formation porte sur la réalisation de 9 projets différents. Vous trouverez ci-dessous l'intitulé des différents projets et les compétences acquises pour chacun d'eux.
# Je suis désormais à la recherche d'un poste en tant que Data Analyst ! je suis pret à demarrer n'importe quand alors n'hésitez pas à me contacter !

# Projet 1 : Faites une analyse des ventes pour un e-commerce

### Contexte :
Dans ce projet, vous travaillez depuis un an en tant que Data Analyst au service Marketing d'une entreprise de grande distribution, Le Grand Marché. Votre mission principale consiste à préparer et analyser les données pour le rapport mensuel des actions marketing, qui sera présenté à la direction. Vous devez sélectionner et interpréter des graphiques pertinents pour expliquer la baisse du chiffre d'affaires et anticiper son évolution.
De plus, vous aidez votre collègue du pôle Marketing à analyser les données des clients affiliés, en mettant à jour les chiffres dans un tableau de bord et en créant des graphiques pour visualiser les performances.
![Capture d’écran 2024-10-16 155040](https://github.com/user-attachments/assets/7c27dbbd-dfbd-4e5d-b7f3-198b100f727f)


### compétences acquises : 
:black_medium_small_square:	 Générer des graphiques adaptés aux types de données

:black_medium_small_square:	 Interpréter les informations provenant d'un dashboard

:black_medium_small_square:	 Synthétiser des résultats à destination d'un client
## Outils utilisés : 
Excel, PowerPoint

## Projet 2 : Créez et utilisez une base de données immobilière avec SQL
![projet 2](https://github.com/user-attachments/assets/734ec1d1-18cb-436f-8cab-ac726f537238)

### Contexte :
Dans ce projet, en tant que Data Analyst chez Laplace Immo, vous êtes chargé d'aider à la mise en place du projet stratégique interne appelé "DATAImmo". Ce projet vise à créer un modèle pour mieux prédire les prix de vente des biens immobiliers à partir de données provenant de diverses sources, telles que les transactions foncières et les données démographiques de l'INSEE. Vous êtes responsable de modifier la base de données, de créer un dictionnaire des données et de concevoir un schéma relationnel normalisé pour faciliter l'analyse des données et l'accompagnement des agences régionales dans leurs décisions. ![Capture d’écran 2024-10-15 154146](https://github.com/user-attachments/assets/14d5c4bf-6526-4eb3-b097-ac9692b4c15a)
                            
### compétences acquises : 
:black_medium_small_square:	 Générer des graphiques adaptés aux types de données

:black_medium_small_square:  Charger des données dans une base de données

:black_medium_small_square:  Créer des tables dans une base de données

:black_medium_small_square:  Créer le schéma d'une base de données

:black_medium_small_square:  Effectuer des requêtes SQL pour répondre à une problématique métier

:black_medium_small_square:  Mettre à jour un catalogue de données
## Outils utilisés : 
mySQL, postgreSQL

## Projet 3 : Réalisez une étude de santé publique avec R ou Python
![Projet 3](https://github.com/user-attachments/assets/2468b4b1-0441-40ac-beef-05b8a392938e)

### Contexte :

Dans ce projet, vous avez récemment rejoint l'équipe de recherche de la FAO (Food and Agriculture Organization of the United Nations) en tant que Data Analyst.  L'un des organes qui compose l'ONU et dont l'objectif est d' « aider à construire un monde libéré de la faim ». Votre équipe est chargée de réaliser une étude de grande ampleur sur le thème de la sous-nutrition dans le monde. Le problème de la faim est complexe et peut avoir de multiples causes, différentes selon les pays. L’étape préliminaire de cette étude sera donc d’établir un “état de l’art” des recherches déjà publiées, mais également de mener une étude statistique destinée à orienter les recherches vers des pays particuliers, et de mettre en lumière différentes causes de la faim.
À votre arrivée, Marc, le responsable de l'équipe, vous a fourni des documents essentiels, dont une ébauche de présentation, un jeu de données, un lexique, ainsi qu'un notebook contenant les étapes préliminaires d'analyse préparées par Julien, l'ancien Data Analyst.
Votre rôle est d'approfondir et d'analyser ces données en utilisant des outils comme Python ou R, avec la possibilité d'ajouter des analyses complémentaires pertinentes. Vous devez également utiliser ces ressources pour produire une présentation concise sur l'état actuel de l'alimentation mondial.

![Capture d’écran 2024-10-16 155443](https://github.com/user-attachments/assets/14540c98-efec-4180-a22e-925b4c8a2c95)

  
### compétences acquises : 
:black_medium_small_square:	 Manipuler des DataFrames

:black_medium_small_square:  Analyser et nettoyer les données ( valeurs manquantes, valeurs aberrantes, doublons...)

:black_medium_small_square:  Utiliser des librairies spécialisées pour les traitements data (Librairie Pandas, Numpy, Scipy et sklearn...)

:black_medium_small_square:  Rédiger et présenter une méthodologie d'exploration et d'analyse des données
## Outils utilisés : 
Algèbre relationnelle ,Language Python / Librairie Pandas, Numpy, Scipy et sklearn.

## Projet 4 : Optimisez la gestion des données d'une boutique avec R ou Python

### Contexte :

Dans ce projet, vous commencez en tant que Data Analyst chez BottleNeck, un marchand de vin prestigieux. Votre manager, vous demande de rapprocher deux bases de données provenant d'un ERP et de la plateforme de vente en ligne de l'entreprise. L'objectif est de calculer le chiffre d'affaires par produit en ligne et de vérifier la cohérence des prix, en identifiant d'éventuelles anomalies. Vous devez également présenter vos résultats lors d'une réunion COPIL, sous forme de présentation ou de notebook. Laurent met à votre disposition deux exports de données ainsi qu'un tableau de liaison entre les deux systèmes pour faciliter votre travail.

![Capture d’écran 2024-10-16 155959](https://github.com/user-attachments/assets/9a3ec794-b712-48ed-bc1b-4e13cab387df)

                 
### compétences acquises : 
:black_medium_small_square:  Analyser et nettoyer les données ( valeurs manquantes, valeurs aberrantes, doublons...)

:black_medium_small_square:	 Réaliser une analyse univariée pour interpréter des données

:black_medium_small_square:  Classifier différents types de données 

:black_medium_small_square:  Gérer les erreurs et les incohérences présentes sur des données stockées : nettoyer,détecter les outilers, rapprocher les données via des jointures...
## Outils utilisés : 
Language Python / Librairie Pandas, Numpy, Scipy et sklearn.

## Projet 5 : Analysez les ventes d'une librairie avec R ou Python
![Capture d’écran 2024-10-16 160338](https://github.com/user-attachments/assets/1e9c20d1-ed57-468b-b487-2adac0c74e88)

### Contexte :
Dans ce projet, vous travaillez en tant que Data Analyst dans un cabinet de conseil spécialisé dans la transformation digitale. la directrice des ressources humaines, vous demande de collaborer avec le contrôleur de gestion sociale, pour automatiser un rapport de diagnostic sur l'égalité femmes-hommes. Ce rapport est requis annuellement pour les entreprises de plus de 50 salariés, dans le cadre de l'obligation de publier l'index de l'égalité femmes-hommes.

Votre mission consiste à utiliser KNIME pour créer un workflow qui génère les graphiques liés à cinq indicateurs d'égalité professionnelle parmi ceux définis par le ministère du Travail. Les données fournies proviennent du Système d'Information des Ressources Humaines (SIRH) et nécessitent une anonymisation conforme au RGPD. Vous devrez également produire un fichier .csv pour des analyses futures dans Tableau Software.
Ce projet vous permettra de contribuer à une stratégie d'égalité professionnelle tout en renforçant la marque employeur du cabinet.

                            
### compétences acquises :

:black_medium_small_square:  Analyser et nettoyer les données ( valeurs manquantes, valeurs aberrantes, doublons...)

:black_medium_small_square:	 Réaliser un test statistique : test de normalité, test chi2, test de Spearman, ANOVA...

:black_medium_small_square:  Réaliser une analyse bivariée pour interpréter des données : analyse des KPI, segmentation des produits,  segmentation des clients, analyse de la saisonnalité...

:black_medium_small_square:  Analyser des séries temporelles :   la série temporelle de l’évolution du chiffre d’affaires,  réaliser une décomposition en moyenne mobile...

## Outils utilisés : 
Language Python / Librairie Pandas, Numpy, Scipy, Sklearn, Seaborn, Matplotlib...

## Projet 6 : Analysez des indicateurs de l'égalité femme-homme avec Knime

### Contexte :
Dans ce projet, Lapage, une ancienne librairie physique, a récemment lancé son site de vente en ligne après avoir rencontré un fort engouement de la part de ses clients. Vous avez été recruté en tant que Data Analyst pour analyser l'activité de la librairie en ligne. L'équipe marketing a des attentes spécifiques : analyser les indicateurs de vente pour évaluer les performances commerciales et réaliser une analyse détaillée du comportement des clients en ligne. Les bases de données nécessaires ( clients, produits, transactions...) sont déjà mises à votre disposition pour démarrer la mission.
![Capture d’écran 2024-10-16 163230](https://github.com/user-attachments/assets/1b9a0abf-c7fc-4392-82af-1388dee21c62)

                            
### compétences acquises :

:black_medium_small_square: Collecter des données en respectant le RGPD

:black_medium_small_square:  Analyser et nettoyer les données sur Knime ( valeurs manquantes, valeurs aberrantes, doublons...)

:black_medium_small_square: Préparer des données pour l'analyse en respectant les normes internes à l’entreprise

:black_medium_small_square: Transférer des données vers une zone de préparation


## Outils utilisés : 
Knime 

## Projet 7 : Faites une étude sur l'eau potable

### Contexte :
Dans le cadre de votre mission en tant que Data Analyst pour l'ONG DWFA, vous êtes chargé de créer un tableau de bord interactif permettant d'identifier les pays confrontés à des difficultés d'accès à l'eau potable. Ce tableau de bord sera essentiel pour orienter les futurs investissements dans l'un des trois domaines d'expertise de DWFA : création de services d'accès à l'eau potable, modernisation de services existants et consulting auprès des gouvernements.

Le chef de mission, vous demande de choisir des indicateurs pertinents pour chaque domaine, puis de concevoir un blueprint (document synthétique des indicateurs) et des mockups (modèles basse fidélité de 3 vues du tableau de bord). Les données fournies par un Data Engineer, ainsi que des informations complémentaires provenant de sources telles que l'OMS et la FAO, seront les bases de votre analyse.

Ce projet permettra de mieux cibler les efforts de l'ONG en fonction du pays qui sera sélectionné, en fonction des fonds reçus.

![Capture d’écran 2024-10-16 223457](https://github.com/user-attachments/assets/167dd957-6105-47a7-9913-4df6de9d466a)

                  
### compétences acquises :

:black_medium_small_square:  Analyser un besoin client pour formuler des questions analytiques

 :black_medium_small_square:   Explorer et nettoyer les données sur Power Query

:black_medium_small_square:  Créer un tableau de bord répondant à des questions analytiques sur Tableau 

:black_medium_small_square:  Générer des graphiques adaptés aux types de données

:black_medium_small_square:  Synthétiser des résultats à destination d'un client

## Outils utilisés : 
Power Bi, Power Query

## Projet 8 : Produisez une étude de marché avec R ou Python

### Contexte :
Dans le cadre de votre mission en tant que Data Analyst chez La Poule qui Chante, une entreprise d’agroalimentaire, vous êtes chargé d’analyser les marchés internationaux potentiels pour l’exportation de leurs produits, notamment leurs poulets. Votre tâche principale consiste à réaliser une analyse de clustering des pays à partir des données fournies par la FAO. L'objectif est de repérer des groupements de pays potentiels où l'entreprise pourrait se développer. Pour cela, vous utiliserez deux méthodes de classification :

:black_small_square: Classification Ascendante Hiérarchique (CAH)

:black_small_square: K-means

Votre analyse aidera La Poule qui Chante à orienter ses efforts de développement international de manière stratégique, en fonction des regroupements de pays identifiés par les algorithmes de clustering.
![Capture d’écran 2024-10-16 223840](https://github.com/user-attachments/assets/16e56b77-29e1-4ae1-b674-339e5decec89)


### compétences acquises :

:black_medium_small_square:  nettoyer et fusionner les données ( valeurs manquantes, outliers, doublons...)

:black_medium_small_square:  Explorer des données pour synthétiser des variables

:black_medium_small_square:  Effectuer un clustering : Clustering hiérarchique et K-Means

:black_medium_small_square:  Réduire  les dimensions des données :  l'analyse des compsantes principales (ACP)
## Outils utilisés : 
Language Python / Librairie Pandas, Numpy, Scipy, Sklearn, Seaborn, Matplotlib...

## Projet 9 : Détectez des faux billets avec R ou Python
![Capture d’écran 2024-10-16 230514](https://github.com/user-attachments/assets/354dd1f9-3163-48b5-91e9-6c8a7ad3e138)

### Contexte :
En tant que Data Analyst pour l’ONCFM, votre mission consiste à développer un modèle capable de distinguer automatiquement les vrais des faux billets en euros en se basant sur leurs dimensions et caractéristiques. Pour ce faire la consigne est d'explorer différentes approches de modélisation (régression logistique, k-means..) pour déterminer le meilleur algorithme de classification des vrais et faux billets.
Présenter les résultats finaux et le modèle retenu, en détaillant les différentes pistes explorées et les traitements effectués.

![Capture d’écran 2024-10-16 225440](https://github.com/user-attachments/assets/9942a71b-e13f-4b48-8c15-269faf6cf427)

### compétences acquises :

:black_medium_small_square:  Opérer des classifications automatiques pour partitionner les données

:black_medium_small_square: Réaliser une analyse prédictive

:black_medium_small_square: Réaliser une régression linéaire

:black_medium_small_square: Réaliser une régression logistique
## Outils utilisés : 
Language Python / Librairie Pandas, Numpy, Scipy, Sklearn, Seaborn, Matplotlib...

